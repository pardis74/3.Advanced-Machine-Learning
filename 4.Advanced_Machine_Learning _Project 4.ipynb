{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\", encoding = 'cp1252')\n",
    "test = pd.read_csv(\"test.csv\", encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    Iâ€™ve seen a lot of bad reviews for this phone ...\n",
       " 1    This phone looks and performs great like it's ...\n",
       " 2    Don't listen to bad reviews! My phone arrived ...\n",
       " 3    Love this phone! I am so glad I bought a refur...\n",
       " 4    First, seller did a great job and I think I go...\n",
       " 5    Received prompt delivery of the phone. I inser...\n",
       " 6    Overall, the phone isn't too bad for the price...\n",
       " 7    The iPhone 7 I purchased was \"certified refurb...\n",
       " 8    Initially I was happy with the phone. It looke...\n",
       " 9    Be cautious - if you have ANY issues at all, r...\n",
       " Name: Review, dtype: object,\n",
       " 0    1\n",
       " 1    1\n",
       " 2    1\n",
       " 3    1\n",
       " 4    1\n",
       " 5    1\n",
       " 6    0\n",
       " 7    0\n",
       " 8    0\n",
       " 9    0\n",
       " Name: Target, dtype: int64,\n",
       " 0    The phone arrived in pretty decent condition. ...\n",
       " 1    iPhone 7 Black came in excellent condition. Li...\n",
       " Name: Review, dtype: object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's take a peek at out training and test datasets\n",
    "train['Review'], train['Target'], test['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything looks fine. Let's proceed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = ['great', 'happy', 'bad', 'return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "import re\n",
    "\n",
    "def build_vocabulary(key_words, text):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "        key_words:   list of key words\n",
    "        text:        text where you search for key words\n",
    "    OUTPUT:\n",
    "        occurrences: list of occurrences of the key words\n",
    "    \"\"\"\n",
    "    occurrences = []\n",
    "    \n",
    "    # we convert all letter into lower case\n",
    "    test_lower = text.lower()\n",
    "    \n",
    "    # and split all word \n",
    "    # (otherwise, word with the same root may be counted instead of the key words\n",
    "    # e.g., ``returned'' will be counted as ``return'')\n",
    "    text_as_words = re.split('[ ,.\\n:;\\|/]', test_lower)\n",
    "    for word in key_words: \n",
    "        n_word = text_as_words.count(word)\n",
    "        occurrences.append(n_word)\n",
    "\n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 0]\n",
      "[1, 1, 0, 1]\n",
      "[1, 1, 1, 0]\n",
      "[1, 1, 0, 0]\n",
      "[1, 1, 1, 0]\n",
      "[0, 1, 0, 0]\n",
      "[0, 0, 3, 1]\n",
      "[1, 0, 1, 0]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "# Let's look what we have now\n",
    "\n",
    "# print and save as X_train lists of occurrences of the key words in the training data\n",
    "X_train = []\n",
    "for i in range(len(train)):\n",
    "    current_occurrences = build_vocabulary(key_words, train['Review'][i])\n",
    "    print(current_occurrences)\n",
    "    X_train.append(current_occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1]\n",
      "[1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# print and save as X_test lists of occurrences of the key words in the training data\n",
    "\n",
    "X_test = []\n",
    "for i in range(len(test)):\n",
    "    current_occurrences = build_vocabulary(key_words, test['Review'][i])\n",
    "    print(current_occurrences)\n",
    "    X_test.append(current_occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# save target values as a list\n",
    "y_train = list(train['Target'])\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] \n",
      " [[0.81274382 0.18725618]\n",
      " [0.43663546 0.56336454]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# we use Multinomial Naive Bayes\n",
    "\n",
    "# alpha is a parameter in a so-called Laplacian smoothing\n",
    "# in our simple model we will not use it, that is why we want to set alpha = 0\n",
    "# alpha = 1.0e-10 (meaning alpha = 0, but Python will not allow this, so we say it is a very small number)\n",
    "\n",
    "# fit_prior = True since we do want to fit our priors, otherwise the uniform distribution will be chosen\n",
    "our_classifier = MultinomialNB(alpha = 1.0e-10, fit_prior = True);\n",
    "our_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_test = our_classifier.predict(X_test)\n",
    "probabilities = our_classifier.predict_proba(X_test)\n",
    "print(y_test, \"\\n\", probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST # 1\n",
      "Probabilities: 0.8127438231342611  vs  0.18725617686573853\n",
      "Prediction: 0 (Negative)\n",
      "TEST # 2\n",
      "Probabilities: 0.43663546178460994  vs  0.5633645382153898\n",
      "Prediction: 1 (Positive)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test)):\n",
    "    print('TEST #', i + 1)\n",
    "    print('Probabilities:', probabilities[i][0], ' vs ', probabilities[i][1])\n",
    "    if y_test[i] == 0:\n",
    "        print('Prediction:', y_test[i], '(Negative)')\n",
    "    else:\n",
    "        print('Prediction:', y_test[i], '(Positive)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is we calculate priors ourselves, and then use the Bayes formula?\n",
    "Let's see and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.812743823146944 0.18725617685305593\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# TEST review #1:\n",
    "\n",
    "# Probability of classifying the review as positive:\n",
    "p1_pos = 6/10 * math.pow(4/15, 1) * math.pow(7/15, 0) * math.pow(3/15, 1) * math.pow(1/15, 1)\n",
    "\n",
    "# Probability of classifying the review as negative:\n",
    "p1_neg = 4/10 * 2/12 * 1 * 5/12 * 4/12\n",
    "\n",
    "print(p1_neg/(p1_pos + p1_neg), p1_pos/(p1_pos + p1_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4366354617856643 0.5633645382143356\n"
     ]
    }
   ],
   "source": [
    "# TEST review #2:\n",
    "\n",
    "# Probability of classifying the review as positive:\n",
    "p2_pos = 6/10 * 4/15 * 7/15 * 3/15 * 1/15\n",
    "\n",
    "# Probability of classifying the review as negative:\n",
    "p2_neg = 4/10 * 2/12 * 1/12 * 5/12 * 4/12\n",
    "\n",
    "print(p2_neg/(p2_pos + p2_neg), p2_pos/(p2_pos + p2_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7152490527998889 0.2847509472001112\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# Probability of classifying the review as positive:\n",
    "p1_pos = 6/10 * math.pow(5/19, 1) * math.pow(8/19, 0) * math.pow(4/19, 1) * math.pow(2/19, 1)\n",
    "\n",
    "# Probability of classifying the review as negative:\n",
    "p1_neg = 4/10 * 3/16 * 1 * 6/16 * 5/16\n",
    "\n",
    "print(p1_neg/(p1_pos + p1_neg), p1_pos/(p1_pos + p1_neg))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a55867a44d7236efbce3179430b255af52391bae5b6f4177f2b850b4b6ea35f4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
